{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load data\n",
    "dataset = loadtxt('./data/data_xgb_class.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.660186\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.634854\n",
      "[2]\tvalidation_0-logloss:0.612239\n",
      "[3]\tvalidation_0-logloss:0.593118\n",
      "[4]\tvalidation_0-logloss:0.578303\n",
      "[5]\tvalidation_0-logloss:0.564942\n",
      "[6]\tvalidation_0-logloss:0.555113\n",
      "[7]\tvalidation_0-logloss:0.54499\n",
      "[8]\tvalidation_0-logloss:0.539151\n",
      "[9]\tvalidation_0-logloss:0.531819\n",
      "[10]\tvalidation_0-logloss:0.526065\n",
      "[11]\tvalidation_0-logloss:0.51977\n",
      "[12]\tvalidation_0-logloss:0.514979\n",
      "[13]\tvalidation_0-logloss:0.50927\n",
      "[14]\tvalidation_0-logloss:0.506086\n",
      "[15]\tvalidation_0-logloss:0.503565\n",
      "[16]\tvalidation_0-logloss:0.503591\n",
      "[17]\tvalidation_0-logloss:0.500805\n",
      "[18]\tvalidation_0-logloss:0.497605\n",
      "[19]\tvalidation_0-logloss:0.495328\n",
      "[20]\tvalidation_0-logloss:0.494777\n",
      "[21]\tvalidation_0-logloss:0.494274\n",
      "[22]\tvalidation_0-logloss:0.493333\n",
      "[23]\tvalidation_0-logloss:0.492211\n",
      "[24]\tvalidation_0-logloss:0.491936\n",
      "[25]\tvalidation_0-logloss:0.490578\n",
      "[26]\tvalidation_0-logloss:0.490895\n",
      "[27]\tvalidation_0-logloss:0.490646\n",
      "[28]\tvalidation_0-logloss:0.491911\n",
      "[29]\tvalidation_0-logloss:0.491407\n",
      "[30]\tvalidation_0-logloss:0.488828\n",
      "[31]\tvalidation_0-logloss:0.487867\n",
      "[32]\tvalidation_0-logloss:0.487297\n",
      "[33]\tvalidation_0-logloss:0.487562\n",
      "[34]\tvalidation_0-logloss:0.487788\n",
      "[35]\tvalidation_0-logloss:0.487962\n",
      "[36]\tvalidation_0-logloss:0.488218\n",
      "[37]\tvalidation_0-logloss:0.489582\n",
      "[38]\tvalidation_0-logloss:0.489334\n",
      "[39]\tvalidation_0-logloss:0.490969\n",
      "[40]\tvalidation_0-logloss:0.48978\n",
      "[41]\tvalidation_0-logloss:0.490704\n",
      "[42]\tvalidation_0-logloss:0.492369\n",
      "Stopping. Best iteration:\n",
      "[32]\tvalidation_0-logloss:0.487297\n",
      "\n",
      "Accuracy: 78.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load data\n",
    "dataset = loadtxt('./data/data_xgb_class.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a13870a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "dataset = loadtxt('./data/data_xgb_class.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.483304 using {'learning_rate': 0.1}\n",
      "-0.689811  with: {'learning_rate': 0.0001}\n",
      "-0.661827  with: {'learning_rate': 0.001}\n",
      "-0.531155  with: {'learning_rate': 0.01}\n",
      "-0.483304  with: {'learning_rate': 0.1}\n",
      "-0.515642  with: {'learning_rate': 0.2}\n",
      "-0.554158  with: {'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Tune learning_rate\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# load data\n",
    "dataset = loadtxt('./data/data_xgb_class.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# grid search\n",
    "model = XGBClassifier()\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learning_rate=learning_rate)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"%f  with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.learning rate\n",
    "2.tree \n",
    "max_depth\n",
    "min_child_weight\n",
    "subsample, colsample_bytree\n",
    "gamma \n",
    "3.正则化参数\n",
    "lambda \n",
    "alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

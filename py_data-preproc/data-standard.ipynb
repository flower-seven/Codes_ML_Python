{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征数据预处理-标准化与归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样我们都需要对原始数据进行处理，少不了的就是 **standardization** (或者叫做 **Z-score normalization**) \n",
    "\n",
    "要求 均值$\\mu = 0$ 和标准差 $\\sigma = 1$\n",
    "\n",
    "转换公式如下：\n",
    "\\begin{equation} z = \\frac{x - \\mu}{\\sigma}\\end{equation} \n",
    "\n",
    "这个意义是十分重大的，想象一下，我们经常通过梯度下降来进行优化求解，公式一般如下，如果特征之间的数值差异太大，那么更新的结果肯定也会产生较大的差异，这是我们所不希望的。在最开始的时候，我们认为特征之间的重要程度的是一样，并不想偏袒哪个特征，所以这部预处理工作必做！\n",
    "\n",
    "$$\\Delta w_j = - \\eta \\frac{\\partial J}{\\partial w_j} = \\eta \\sum_i (t^{(i)} - o^{(i)})x^{(i)}_{j},$$\n",
    "\n",
    "参数更新： \n",
    "\n",
    "$$w_j := w_j + \\Delta w_j,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='About-Min-Max-scaling-normalization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种方法叫做 **Min-Max scaling** (或者叫做 \"normalization\"也就是我们常说的0-1归一化).  \n",
    "处理后的所有特征的值都会被压缩到 0到1区间上.这样做还可以抑制离群值对结果的影响.\n",
    "归一化公式如下：\n",
    "\n",
    "\\begin{equation} X_{norm} = \\frac{X - X_{min}}{X_{max}-X_{min}} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing 和 Normalizing的Scikit-learn实现 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wine dataset consists of 3 different classes where each row correspond to a particular wine sample.\n",
    "\n",
    "The class labels (1, 2, 3) are listed in the first column, and the columns 2-14 correspond to 13 different attributes (features):\n",
    "\n",
    "1) Alcohol  \n",
    "2) Malic acid  \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./data/data_wine_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-198f8fe194a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'./data/data_wine_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#葡萄酒数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m#用哪行当做列名，我们自己来指定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m      \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#返回一个子集，我们拿部分特征举例就可以了\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./data/data_wine_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\n",
    "    './data/wine_data.csv',  #葡萄酒数据集\n",
    "     header=None,     #用哪行当做列名，我们自己来指定\n",
    "     usecols=[0,1,2]  #返回一个子集，我们拿部分特征举例就可以了\n",
    "    )\n",
    "\n",
    "df.columns=['Class label', 'Alcohol', 'Malic acid']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据中，Alcohol和Malic acid 衡量的标准应该是不同的，特征之间数值差异较大\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization and Min-Max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_std = std_scale.transform(df[['Alcohol', 'Malic acid']])\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_minmax = minmax_scale.transform(df[['Alcohol', 'Malic acid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].mean(), df_std[:,1].mean()))\n",
    "print('\\nStandard deviation after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].std(), df_std[:,1].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min-value after min-max scaling:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_minmax[:,0].min(), df_minmax[:,1].min()))\n",
    "print('\\nMax-value after min-max scaling:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_minmax[:,0].max(), df_minmax[:,1].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot():\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.scatter(df['Alcohol'], df['Malic acid'], \n",
    "            color='green', label='input scale', alpha=0.5)\n",
    "\n",
    "    plt.scatter(df_std[:,0], df_std[:,1], color='red', \n",
    "            label='Standardized [$N  (\\mu=0, \\; \\sigma=1)$]', alpha=0.3)\n",
    "\n",
    "    plt.scatter(df_minmax[:,0], df_minmax[:,1], \n",
    "            color='blue', label='min-max scaled [min=0, max=1]', alpha=0.3)\n",
    "\n",
    "    plt.title('Alcohol and Malic Acid content of the wine dataset')\n",
    "    plt.xlabel('Alcohol')\n",
    "    plt.ylabel('Malic Acid')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将原始的和变换后都放到了同一个图上，观察下结果吧！接下来我们再看看数据是否被打乱了呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(6,14))\n",
    "\n",
    "for a,d,l in zip(range(len(ax)), \n",
    "               (df[['Alcohol', 'Malic acid']].values, df_std, df_minmax),\n",
    "               ('Input scale', \n",
    "                'Standardized [$N  (\\mu=0, \\; \\sigma=1)$]', \n",
    "                'min-max scaled [min=0, max=1]')\n",
    "                ):\n",
    "    for i,c in zip(range(1,4), ('red', 'blue', 'green')):\n",
    "        ax[a].scatter(d[df['Class label'].values == i, 0], \n",
    "                  d[df['Class label'].values == i, 1],\n",
    "                  alpha=0.5,\n",
    "                  color=c,\n",
    "                  label='Class %s' %i\n",
    "                  )\n",
    "    ax[a].set_title(l)\n",
    "    ax[a].set_xlabel('Alcohol')\n",
    "    ax[a].set_ylabel('Malic Acid')\n",
    "    ax[a].legend(loc='upper left')\n",
    "    ax[a].grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，如果我们对训练集做了上述处理，那么同样的对测试集也必须要经过相同的处理\n",
    "<pre>\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化处理对PCA主成分分析的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主成分分析（PCA）和一个非常有用的套路，接下来，咱们来看看数据经过标准化处理和未经标准化处理后使用PCA的效果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Sections)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '../data/wine_data.csv', \n",
    "    header=None,\n",
    "    )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the dataset into a separate training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will randomly divide the wine dataset into a training dataset and a test dataset where the training dataset will contain 70% of the samples and the test dataset will contain 30%, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_wine = df.values[:,1:]\n",
    "y_wine = df.values[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine,\n",
    "    test_size=0.30, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling - Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用PCA进行降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们在标准化和非标准化数据集上执行PCA，将数据集转换成二维特征子空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# on non-standardized data\n",
    "pca = PCA(n_components=2).fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# om standardized data\n",
    "pca_std = PCA(n_components=2).fit(X_train_std)\n",
    "X_train_std = pca_std.transform(X_train_std)\n",
    "X_test_std = pca_std.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来看看效果咋样吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "\n",
    "for l,c,m in zip(range(1,4), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax1.scatter(X_train[y_train==l, 0], X_train[y_train==l, 1],\n",
    "        color=c, \n",
    "        label='class %s' %l, \n",
    "        alpha=0.5,\n",
    "        marker=m\n",
    "        )\n",
    "\n",
    "for l,c,m in zip(range(1,4), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax2.scatter(X_train_std[y_train==l, 0], X_train_std[y_train==l, 1],\n",
    "        color=c, \n",
    "        label='class %s' %l, \n",
    "        alpha=0.5,\n",
    "        marker=m\n",
    "        )\n",
    "\n",
    "ax1.set_title('Transformed NON-standardized training dataset after PCA')    \n",
    "ax2.set_title('Transformed standardized training dataset after PCA')    \n",
    "    \n",
    "for ax in (ax1, ax2):\n",
    "\n",
    "    ax.set_xlabel('1st principal component')\n",
    "    ax.set_ylabel('2nd principal component')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直观上，可以清晰的看到经过标准化的数据可分性更强的"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
